{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# config\n",
    "class SetupCFG:\n",
    "  def __init__(self, dataset_name, path_to_dataset, json_name, path_to_weights, path_to_mask, \\\n",
    "               work_dir, video_file_name, video_file_name_to_save, temporary_storage):\n",
    "    self.dataset_name = dataset_name\n",
    "    self.path_to_dataset = path_to_dataset\n",
    "    self.path_to_json = os.path.join(path_to_dataset, json_name)    \n",
    "    self.path_to_weights = path_to_weights\n",
    "    self.path_to_mask = path_to_mask\n",
    "    self.work_dir = work_dir\n",
    "    self.video_file_name = video_file_name\n",
    "    self.video_file_name_to_save = video_file_name_to_save if temporary_storage else os.path.join(work_dir, video_file_name_to_save)\n",
    "    self.temporary_storage = temporary_storage\n",
    "\n",
    "my_cfg = SetupCFG(dataset_name = \"my_dataset\", \n",
    "                  path_to_dataset = \"raw/KomPol2_clean\", \n",
    "                  json_name = \"KomPol2-7.json\", \n",
    "                  work_dir = \"drive/My Drive/Colab Notebooks/output_Pol\",                  \n",
    "                  path_to_weights = \"drive/My Drive/Colab Notebooks/output_Pol/model_final_poliklinika_total_loss_0.9683.pth\",\n",
    "                  #\"drive/My Drive/Colab Notebooks/output_Pol/model_final_poliklinika.pth\",\n",
    "                  path_to_mask = \"images/mask.png\",\n",
    "                  video_file_name = \"raw/videos/cut_final_10sek_v2.mp4\",\n",
    "                  video_file_name_to_save = \"raw/videos/cut_final_10sek_v2_final_with_crossing.mp4\", \n",
    "                  temporary_storage = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import torch, torchvision\n",
    "import detectron2\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from IPython.display import Image \n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "# для регистрации данных\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "# для обучения\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "# для предиктора\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "# для предсказания фото\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "# для предсказания видео\n",
    "from IPython.display import YouTubeVideo, display\n",
    "import tqdm\n",
    "from detectron2.utils.video_visualizer import VideoVisualizer\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(my_cfg.dataset_name, {}, my_cfg.path_to_json, my_cfg.path_to_dataset)\n",
    "MetadataCatalog.get(my_cfg.dataset_name).thing_classes = ['car', 'minibus', 'trolleybus', 'tram', 'truck', 'bus', 'middle_bus', 'ambulance', 'fire_truck', 'middle_truck', 'tractor', 'uncategorized', 'van', 'person']\n",
    "dataset_metadata = MetadataCatalog.get(my_cfg.dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/11 22:31:19 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=14, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=52, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/11 22:31:20 d2.data.datasets.coco]: \u001b[0mLoaded 750 images in COCO format from raw/KomPol2_clean/KomPol2-7.json\n",
      "\u001b[32m[03/11 22:31:20 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 750 images left.\n",
      "\u001b[32m[03/11 22:31:20 d2.data.build]: \u001b[0mDistribution of instances among all 14 categories:\n",
      "\u001b[36m|   category   | #instances   |  category  | #instances   |   category    | #instances   |\n",
      "|:------------:|:-------------|:----------:|:-------------|:-------------:|:-------------|\n",
      "|     car      | 8087         |  minibus   | 1128         |  trolleybus   | 216          |\n",
      "|     tram     | 1            |   truck    | 55           |      bus      | 62           |\n",
      "|  middle_bus  | 575          | ambulance  | 8            |  fire_truck   | 0            |\n",
      "| middle_truck | 289          |  tractor   | 6            | uncategorized | 4927         |\n",
      "|     van      | 69           |   person   | 10560        |               |              |\n",
      "|    total     | 25983        |            |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/11 22:31:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/11 22:31:20 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/11 22:31:20 d2.data.common]: \u001b[0mSerializing 750 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/11 22:31:20 d2.data.common]: \u001b[0mSerialized dataset takes 7.54 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_280758.pkl: 167MB [01:14, 2.25MB/s]                              \n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (14, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (14,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (52, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (52,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/11 22:32:34 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/nir/detecting-traffic-violations-app/venv/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:217: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  num_fg = fg_inds.nonzero().numel()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/11 22:32:51 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 19  total_loss: 3.199  loss_cls: 2.144  loss_box_reg: 0.6108  loss_rpn_cls: 0.1958  loss_rpn_loc: 0.2942  time: 0.8333  data_time: 0.0137  lr: 0.00049953  max_mem: 2640M\n",
      "\u001b[32m[03/11 22:33:07 d2.utils.events]: \u001b[0m eta: 0:03:31  iter: 39  total_loss: 1.932  loss_cls: 0.7414  loss_box_reg: 0.5807  loss_rpn_cls: 0.1276  loss_rpn_loc: 0.2656  time: 0.8112  data_time: 0.0031  lr: 0.00099902  max_mem: 2640M\n",
      "\u001b[32m[03/11 22:33:23 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 59  total_loss: 1.551  loss_cls: 0.5373  loss_box_reg: 0.5714  loss_rpn_cls: 0.09866  loss_rpn_loc: 0.252  time: 0.8160  data_time: 0.0033  lr: 0.0014985  max_mem: 2640M\n",
      "\u001b[32m[03/11 22:33:39 d2.utils.events]: \u001b[0m eta: 0:02:58  iter: 79  total_loss: 1.339  loss_cls: 0.3971  loss_box_reg: 0.4849  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.3198  time: 0.8127  data_time: 0.0030  lr: 0.001998  max_mem: 2640M\n",
      "\u001b[32m[03/11 22:33:55 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 99  total_loss: 1.387  loss_cls: 0.4057  loss_box_reg: 0.4687  loss_rpn_cls: 0.08373  loss_rpn_loc: 0.3318  time: 0.8132  data_time: 0.0031  lr: 0.0024975  max_mem: 2640M\n",
      "\u001b[32m[03/11 22:34:13 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 119  total_loss: 1.104  loss_cls: 0.339  loss_box_reg: 0.454  loss_rpn_cls: 0.08757  loss_rpn_loc: 0.2179  time: 0.8238  data_time: 0.0034  lr: 0.002997  max_mem: 2640M\n",
      "\u001b[32m[03/11 22:34:30 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 139  total_loss: 1.123  loss_cls: 0.3277  loss_box_reg: 0.4404  loss_rpn_cls: 0.07048  loss_rpn_loc: 0.2743  time: 0.8274  data_time: 0.0033  lr: 0.0034965  max_mem: 2640M\n",
      "\u001b[32m[03/11 22:34:49 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 159  total_loss: 1.075  loss_cls: 0.3108  loss_box_reg: 0.4379  loss_rpn_cls: 0.06529  loss_rpn_loc: 0.2197  time: 0.8409  data_time: 0.0036  lr: 0.003996  max_mem: 2640M\n",
      "\u001b[32m[03/11 22:35:07 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 179  total_loss: 1.222  loss_cls: 0.3783  loss_box_reg: 0.4365  loss_rpn_cls: 0.08237  loss_rpn_loc: 0.3029  time: 0.8481  data_time: 0.0044  lr: 0.0044955  max_mem: 2676M\n",
      "\u001b[32m[03/11 22:35:25 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 199  total_loss: 1.158  loss_cls: 0.3106  loss_box_reg: 0.408  loss_rpn_cls: 0.07008  loss_rpn_loc: 0.2352  time: 0.8560  data_time: 0.0041  lr: 0.004995  max_mem: 2676M\n",
      "\u001b[32m[03/11 22:35:43 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 219  total_loss: 1.155  loss_cls: 0.3151  loss_box_reg: 0.4471  loss_rpn_cls: 0.07878  loss_rpn_loc: 0.2712  time: 0.8600  data_time: 0.0038  lr: 0.0054945  max_mem: 2676M\n",
      "\u001b[32m[03/11 22:36:01 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 239  total_loss: 1.216  loss_cls: 0.3234  loss_box_reg: 0.4208  loss_rpn_cls: 0.06379  loss_rpn_loc: 0.3862  time: 0.8601  data_time: 0.0040  lr: 0.005994  max_mem: 2676M\n",
      "\u001b[32m[03/11 22:36:18 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 259  total_loss: 1.065  loss_cls: 0.274  loss_box_reg: 0.4137  loss_rpn_cls: 0.09207  loss_rpn_loc: 0.3037  time: 0.8621  data_time: 0.0041  lr: 0.0064935  max_mem: 2676M\n",
      "\u001b[32m[03/11 22:36:36 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 279  total_loss: 1.107  loss_cls: 0.2619  loss_box_reg: 0.3903  loss_rpn_cls: 0.07451  loss_rpn_loc: 0.307  time: 0.8633  data_time: 0.0052  lr: 0.006993  max_mem: 2676M\n",
      "\u001b[32m[03/11 22:36:55 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 299  total_loss: 1.173  loss_cls: 0.3077  loss_box_reg: 0.4074  loss_rpn_cls: 0.08235  loss_rpn_loc: 0.3088  time: 0.8642  data_time: 0.0076  lr: 0.0074925  max_mem: 2676M\n",
      "\u001b[32m[03/11 22:36:55 d2.engine.hooks]: \u001b[0mOverall training speed: 298 iterations in 0:04:17 (0.8642 s / it)\n",
      "\u001b[32m[03/11 22:36:55 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:19 (0:00:01 on hooks)\n",
      "\u001b[32m[03/11 22:36:55 d2.data.datasets.coco]: \u001b[0mLoaded 750 images in COCO format from raw/KomPol2_clean/KomPol2-7.json\n",
      "\u001b[32m[03/11 22:36:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/11 22:36:55 d2.data.common]: \u001b[0mSerializing 750 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/11 22:36:55 d2.data.common]: \u001b[0mSerialized dataset takes 7.54 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/11 22:36:55 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")) #LVIS-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\n",
    "cfg.DATASETS.TRAIN = (my_cfg.dataset_name,)\n",
    "cfg.DATASETS.TEST = (my_cfg.dataset_name,)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4 #8\n",
    "# cfg.MODEL.WEIGHTS = my_cfg.path_to_weights\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo \n",
    "cfg.SOLVER.IMS_PER_BATCH = 2 #5\n",
    "cfg.SOLVER.BASE_LR = 0.025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 300   # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128 #512  # faster, and good enough for this toy dataset (default: 512) 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 13 #10 \n",
    "# cfg.MODEL.RETINANET.PRIOR_PROB = 1\n",
    "\n",
    "\n",
    "os.makedirs(\"./output\", exist_ok=True) # cfg.OUTPUT_DIR\n",
    "cfg.OUTPUT_DIR = \"./output\"\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
